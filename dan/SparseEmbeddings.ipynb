{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8g2Xcxxw8FR"
   },
   "source": [
    "## TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UuOwAvPH2CWK",
    "outputId": "e1507cd0-1051-49c6-9ecf-c0727aae120a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Counts:\n",
      " analysis  application  classification  document  embeddings  helps  identify  idf  important  improve  in  is  key  nlp  popular  semantic  technique  text  tf  understanding  word  words\n",
      "        0            0               0         1           0      1         1    1          1        0   1   0    0    0        0         0          0     0   1              0     0      1\n",
      "        0            1               1         0           0      0         0    0          0        0   0   1    0    1        1         0          0     1   0              0     0      0\n",
      "        0            0               0         0           1      0         0    0          0        1   0   0    0    0        0         1          0     0   0              1     1      0\n",
      "        1            0               0         0           0      0         0    1          0        0   1   1    1    0        0         0          1     1   1              0     0      0\n",
      "\n",
      "Normalised Counts:\n",
      " analysis  application  classification  document  embeddings  helps  identify  idf  important  improve   in   is  key  nlp  popular  semantic  technique  text   tf  understanding  word  words\n",
      "     0.00         0.00            0.00      0.12         0.0   0.12      0.12 0.12       0.12      0.0 0.12 0.00 0.00 0.00     0.00       0.0       0.00  0.00 0.12            0.0   0.0   0.12\n",
      "     0.00         0.17            0.17      0.00         0.0   0.00      0.00 0.00       0.00      0.0 0.00 0.17 0.00 0.17     0.17       0.0       0.00  0.17 0.00            0.0   0.0   0.00\n",
      "     0.00         0.00            0.00      0.00         0.2   0.00      0.00 0.00       0.00      0.2 0.00 0.00 0.00 0.00     0.00       0.2       0.00  0.00 0.00            0.2   0.2   0.00\n",
      "     0.12         0.00            0.00      0.00         0.0   0.00      0.00 0.12       0.00      0.0 0.12 0.12 0.12 0.00     0.00       0.0       0.12  0.12 0.12            0.0   0.0   0.00\n",
      "\n",
      "TF-IDF Matrix:\n",
      " analysis  application  classification  document  embeddings  helps  identify  idf  important  improve   in   is  key  nlp  popular  semantic  technique  text   tf  understanding  word  words\n",
      "      0.0         0.00            0.00      0.38        0.00   0.38      0.38 0.30       0.38     0.00 0.30 0.00  0.0 0.00     0.00      0.00        0.0  0.00 0.30           0.00  0.00   0.38\n",
      "      0.0         0.44            0.44      0.00        0.00   0.00      0.00 0.00       0.00     0.00 0.00 0.34  0.0 0.44     0.44      0.00        0.0  0.34 0.00           0.00  0.00   0.00\n",
      "      0.0         0.00            0.00      0.00        0.45   0.00      0.00 0.00       0.00     0.45 0.00 0.00  0.0 0.00     0.00      0.45        0.0  0.00 0.00           0.45  0.45   0.00\n",
      "      0.4         0.00            0.00      0.00        0.00   0.00      0.00 0.32       0.00     0.00 0.32 0.32  0.4 0.00     0.00      0.00        0.4  0.32 0.32           0.00  0.00   0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample text documents\n",
    "documents = [\n",
    "    \"TF-IDF helps identify important words in a document.\",\n",
    "    \"Text classification is a popular NLP application.\",\n",
    "    \"Word embeddings improve semantic understanding.\",\n",
    "    \"TF-IDF is a key technique in text analysis.\"\n",
    "]\n",
    "\n",
    "# Compute raw counts using CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "raw_count_matrix = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Normalise raw counts (divide each word count by the total word count in the document)\n",
    "raw_count_array = raw_count_matrix.toarray()\n",
    "normalised_counts = raw_count_array / raw_count_array.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Convert raw counts and normalised counts to DataFrames\n",
    "feature_names = count_vectorizer.get_feature_names_out()\n",
    "raw_count_df = pd.DataFrame(raw_count_array, columns=feature_names).round(2)\n",
    "normalised_count_df = pd.DataFrame(normalised_counts, columns=feature_names).round(2)\n",
    "\n",
    "# Compute TF-IDF values using TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out()).round(2)\n",
    "\n",
    "# Ensure all columns and rows are displayed in full when printing\n",
    "pd.set_option(\"display.max_columns\", None)  # Ensure all columns are printed\n",
    "pd.set_option(\"display.width\", 1000)  # Set the display width to prevent line breaks\n",
    "pd.set_option(\"display.max_rows\", None)  # Ensure all rows are printed\n",
    "\n",
    "# Display results\n",
    "print(\"Raw Counts:\")\n",
    "print(raw_count_df.to_string(index=False))  # Print the full table without splitting\n",
    "\n",
    "print(\"\\nNormalised Counts:\")\n",
    "print(normalised_count_df.to_string(index=False))  # Print the full table without splitting\n",
    "\n",
    "print(\"\\nTF-IDF Matrix:\")\n",
    "print(tfidf_df.to_string(index=False))  # Print the full table without splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IwG8m8jb5Ws4",
    "outputId": "c7e29dc6-e4d5-41fb-df6e-78261b5546a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Counts:\n",
      " analysis  application  classification  document  embeddings  helps  identify  important  improve  in  is  key  nlp  popular  semantic  technique  text  tf-idf  understanding  word  words\n",
      "        0            0               0         1           0      1         1          1        0   1   0    0    0        0         0          0     0       1              0     0      1\n",
      "        0            1               1         0           0      0         0          0        0   0   1    0    1        1         0          0     1       0              0     0      0\n",
      "        0            0               0         0           1      0         0          0        1   0   0    0    0        0         1          0     0       0              1     1      0\n",
      "        1            0               0         0           0      0         0          0        0   1   1    1    0        0         0          1     1       1              0     0      0\n",
      "\n",
      "Normalised Counts:\n",
      " analysis  application  classification  document  embeddings  helps  identify  important  improve   in   is  key  nlp  popular  semantic  technique  text  tf-idf  understanding  word  words\n",
      "     0.00         0.00            0.00      0.14         0.0   0.14      0.14       0.14      0.0 0.14 0.00 0.00 0.00     0.00       0.0       0.00  0.00    0.14            0.0   0.0   0.14\n",
      "     0.00         0.17            0.17      0.00         0.0   0.00      0.00       0.00      0.0 0.00 0.17 0.00 0.17     0.17       0.0       0.00  0.17    0.00            0.0   0.0   0.00\n",
      "     0.00         0.00            0.00      0.00         0.2   0.00      0.00       0.00      0.2 0.00 0.00 0.00 0.00     0.00       0.2       0.00  0.00    0.00            0.2   0.2   0.00\n",
      "     0.14         0.00            0.00      0.00         0.0   0.00      0.00       0.00      0.0 0.14 0.14 0.14 0.00     0.00       0.0       0.14  0.14    0.14            0.0   0.0   0.00\n",
      "\n",
      "TF-IDF Matrix:\n",
      " analysis  application  classification  document  embeddings  helps  identify  important  improve   in   is  key  nlp  popular  semantic  technique  text  tf-idf  understanding  word  words\n",
      "     0.00         0.00            0.00       0.4        0.00    0.4       0.4        0.4     0.00 0.32 0.00 0.00 0.00     0.00      0.00       0.00  0.00    0.32           0.00  0.00    0.4\n",
      "     0.00         0.44            0.44       0.0        0.00    0.0       0.0        0.0     0.00 0.00 0.34 0.00 0.44     0.44      0.00       0.00  0.34    0.00           0.00  0.00    0.0\n",
      "     0.00         0.00            0.00       0.0        0.45    0.0       0.0        0.0     0.45 0.00 0.00 0.00 0.00     0.00      0.45       0.00  0.00    0.00           0.45  0.45    0.0\n",
      "     0.43         0.00            0.00       0.0        0.00    0.0       0.0        0.0     0.00 0.34 0.34 0.43 0.00     0.00      0.00       0.43  0.34    0.34           0.00  0.00    0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample text documents\n",
    "documents = [\n",
    "    \"TF-IDF helps identify important words in a document.\",\n",
    "    \"Text classification is a popular NLP application.\",\n",
    "    \"Word embeddings improve semantic understanding.\",\n",
    "    \"TF-IDF is a key technique in text analysis.\"\n",
    "]\n",
    "\n",
    "# Compute raw counts using CountVectorizer with custom token pattern\n",
    "count_vectorizer = CountVectorizer(token_pattern=r\"\\b\\w+[-]?\\w+\\b\")  # regular expression to handle hyphenated words\n",
    "raw_count_matrix = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Normalise raw counts (divide each word count by the total word count in the document)\n",
    "raw_count_array = raw_count_matrix.toarray()  # Convert sparse matrix to dense NumPy array\n",
    "normalised_counts = raw_count_array / raw_count_array.sum(axis=1, keepdims=True)  # Perform normalisation\n",
    "\n",
    "# Convert raw counts and normalised counts to DataFrames\n",
    "feature_names = count_vectorizer.get_feature_names_out()\n",
    "raw_count_df = pd.DataFrame(raw_count_array, columns=feature_names).round(2)\n",
    "normalised_count_df = pd.DataFrame(normalised_counts, columns=feature_names).round(2)\n",
    "\n",
    "# Compute TF-IDF values using TfidfVectorizer with custom token pattern\n",
    "tfidf_vectorizer = TfidfVectorizer(token_pattern=r\"\\b\\w+[-]?\\w+\\b\")  # Use the same regex\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out()).round(2)\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 1000)  # Set the display width to prevent line breaks\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "\n",
    "print(\"Raw Counts:\")\n",
    "print(raw_count_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nNormalised Counts:\")\n",
    "print(normalised_count_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nTF-IDF Matrix:\")\n",
    "print(tfidf_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jE8ifph9z4jx",
    "outputId": "21178b11-404a-4b5f-dc56-8c659650ff1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which document mentions the importance of TF-IDF?\n",
      "\n",
      "\n",
      "Cosine Similarities:\n",
      "Document 1: 0.5096\n",
      "Document 2: 0.0000\n",
      "Document 3: 0.0000\n",
      "Document 4: 0.2084\n",
      "\n",
      "The document that best answers the question is:\n",
      "'TF-IDF helps identify important words in a document.'\n"
     ]
    }
   ],
   "source": [
    "question = \"Which document mentions the importance of TF-IDF?\"\n",
    "tfidf_question = tfidf_vectorizer.transform([question])\n",
    "\n",
    "#Compute cosine similarity between the question and each document\n",
    "cosine_similarities = (tfidf_matrix @ tfidf_question.T).toarray().flatten()\n",
    "\n",
    "#Identify the document with the highest similarity\n",
    "most_relevant_index = np.argmax(cosine_similarities)\n",
    "most_relevant_document = documents[most_relevant_index]\n",
    "\n",
    "# Display Results\n",
    "print(f\"Question: {question}\\n\")\n",
    "#print(\"TF-IDF Matrix:\")\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "#print(tfidf_df)\n",
    "\n",
    "print(\"\\nCosine Similarities:\")\n",
    "for i, score in enumerate(cosine_similarities):\n",
    "    print(f\"Document {i + 1}: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nThe document that best answers the question is:\\n'{most_relevant_document}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
